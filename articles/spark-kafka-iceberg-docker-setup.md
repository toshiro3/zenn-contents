---
title: "Spark Structured Streaming + Kafka + Iceberg ç’°å¢ƒæ§‹ç¯‰ï¼ˆDocker Composeï¼‰"
emoji: "ğŸ³"
type: "tech"
topics: ["spark", "kafka", "iceberg", "docker", "streaming"]
published: true
---

## ã¯ã˜ã‚ã«

ã“ã®è¨˜äº‹ã§ã¯ã€**Spark Structured Streaming + Kafka + Apache Iceberg** ã‚’ä½¿ã£ãŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ­ãƒ¼ã‚«ãƒ«æ¤œè¨¼ç’°å¢ƒã‚’ Docker Compose ã§æ§‹ç¯‰ã—ã¾ã™ã€‚

Kafka ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€Iceberg ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ›¸ãè¾¼ã‚€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ç¬¬ä¸€æ­©ã¨ã—ã¦ã€ã¾ãšã¯ç’°å¢ƒæ§‹ç¯‰ã¨å‹•ä½œç¢ºèªã‚’è¡Œã„ã¾ã™ã€‚

## ãªãœ Spark Structured Streaming ãªã®ã‹ï¼Ÿ

ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã§ Iceberg ã«æ›¸ãè¾¼ã‚€æ–¹æ³•ã¨ã—ã¦ã€AWS ã§ã¯ä»¥ä¸‹ã®é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™ï¼š

- **AWS Glue Streaming**ï¼ˆSpark Structured Streaming ãƒ™ãƒ¼ã‚¹ï¼‰
- **Amazon Managed Service for Apache Flink**
- **Amazon EMR**ï¼ˆSpark / Flinkï¼‰

æœ¬ã‚·ãƒªãƒ¼ã‚ºã§ã¯ Spark Structured Streaming ã‚’æ¡ç”¨ã—ã¾ã™ã€‚ç†ç”±ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š

1. **Spark ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã¨ã®è¦ªå’Œæ€§**: æ—¢å­˜ã® Spark ãƒãƒƒãƒå‡¦ç†ã¨ã®çµ±åˆãŒå®¹æ˜“
2. **AWS Glue ã¨ã®é€£æº**: ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã§ã®é‹ç”¨ãŒå¯èƒ½
3. **å­¦ç¿’ã‚³ã‚¹ãƒˆ**: Spark DataFrame API ã®å»¶é•·ã§å­¦ã¹ã‚‹

## æ§‹æˆæ¦‚è¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka     â”‚â”€â”€â”€â–¶â”‚   Spark     â”‚â”€â”€â”€â–¶â”‚  Iceberg    â”‚
â”‚  (Source)   â”‚    â”‚ Structured  â”‚    â”‚  (MinIO)    â”‚
â”‚             â”‚    â”‚ Streaming   â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                   â”‚ REST Catalog â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä½¿ç”¨ã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | ã‚¤ãƒ¡ãƒ¼ã‚¸ | å½¹å‰² |
|--------------|---------|------|
| Spark | tabulario/spark-iceberg:latest | ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç† + Jupyter Notebook |
| Iceberg REST Catalog | apache/iceberg-rest-fixture:latest | ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç† |
| MinIO | minio/minio:latest | S3 äº’æ›ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ |
| Kafka | apache/kafka:4.1.1 | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ–ãƒ­ãƒ¼ã‚«ãƒ¼ï¼ˆKRaft modeï¼‰ |
| Kafka UI | provectuslabs/kafka-ui:latest | Kafka ç®¡ç† UI |

## ç’°å¢ƒæ§‹ç¯‰

æœ¬è¨˜äº‹ã§ä½¿ç”¨ã™ã‚‹ç’°å¢ƒã¯GitHubãƒªãƒã‚¸ãƒˆãƒªã§å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚

@[card](https://github.com/toshiro3/spark-kafka-iceberg-lab)

```bash
git clone https://github.com/toshiro3/spark-kafka-iceberg-lab.git
cd spark-kafka-iceberg-lab
docker compose up -d
```

åˆå›èµ·å‹•æ™‚ã¯ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ Kafka connector ã®å–å¾—ã«æ•°åˆ†ã‹ã‹ã‚Šã¾ã™ã€‚

```bash
# èµ·å‹•çŠ¶æ³ã®ç¢ºèª
docker compose ps
```

ã™ã¹ã¦ã®ã‚³ãƒ³ãƒ†ãƒŠãŒ `Up` ã«ãªã£ã¦ã„ã‚Œã°æˆåŠŸã§ã™ã€‚

### æ§‹æˆãƒ•ã‚¡ã‚¤ãƒ«

ãƒªãƒã‚¸ãƒˆãƒªã«ã¯ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼š

| ãƒ•ã‚¡ã‚¤ãƒ« | èª¬æ˜ |
|---------|------|
| `docker-compose.yml` | å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å®šç¾© |
| `spark-defaults.conf` | Sparkè¨­å®šï¼ˆKafka connectorå«ã‚€ï¼‰ |
| `notebooks/00_environment_check.ipynb` | å‹•ä½œç¢ºèªç”¨Notebook |

### ãƒã‚¤ãƒ³ãƒˆï¼šKafka connector ã®è¿½åŠ 

`tabulario/spark-iceberg` ã‚¤ãƒ¡ãƒ¼ã‚¸ã«ã¯ Kafka connector ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`spark-defaults.conf` ã§ä»¥ä¸‹ã®è¨­å®šã‚’è¿½åŠ ã—ã¦ã„ã¾ã™ï¼š

```conf
spark.jars.packages  org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1
```

ã“ã‚Œã«ã‚ˆã‚Šã€Spark èµ·å‹•æ™‚ã« Kafka connector ãŒè‡ªå‹•çš„ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚

## å‹•ä½œç¢ºèª

### ã‚¢ã‚¯ã‚»ã‚¹ URL

| ã‚µãƒ¼ãƒ“ã‚¹ | URL |
|---------|-----|
| Jupyter Notebook | http://localhost:8888 |
| MinIO Console | http://localhost:9001 |
| Kafka UI | http://localhost:8082 |
| Spark UI | http://localhost:4040 |

### Notebook ã«ã‚ˆã‚‹ç¢ºèª

`notebooks/00_environment_check.ipynb` ã‚’é–‹ã„ã¦ã€å„ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

#### 1. SparkSession ã®ç¢ºèª

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()

print("SparkSession å–å¾—å®Œäº†!")
print(f"Version: {spark.version}")
spark
```

#### 2. Iceberg ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ

```python
# Namespace ã®ä½œæˆ
spark.sql("CREATE NAMESPACE IF NOT EXISTS demo.test_ns")

# ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
spark.sql("""
    CREATE TABLE IF NOT EXISTS demo.test_ns.sample_table (
        id INT,
        name STRING,
        created_at TIMESTAMP
    ) USING iceberg
""")

# ãƒ‡ãƒ¼ã‚¿ã®æŒ¿å…¥
spark.sql("""
    INSERT INTO demo.test_ns.sample_table VALUES 
        (1, 'Alice', current_timestamp()),
        (2, 'Bob', current_timestamp())
""")

spark.sql("SELECT * FROM demo.test_ns.sample_table").show()
```

#### 3. Kafka ã¸ã®æ›¸ãè¾¼ã¿ãƒ»èª­ã¿è¾¼ã¿

```python
# Kafka ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
test_data = [
    ("key1", '{"id": 1, "value": "test1"}'),
    ("key2", '{"id": 2, "value": "test2"}')
]

df_to_kafka = spark.createDataFrame(test_data, ["key", "value"])

df_to_kafka.write \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9092") \
    .option("topic", "test-topic") \
    .save()
```

```python
# Kafka ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿
df_from_kafka = spark.read \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9092") \
    .option("subscribe", "test-topic") \
    .option("startingOffsets", "earliest") \
    .load()

df_from_kafka.selectExpr(
    "CAST(key AS STRING)",
    "CAST(value AS STRING)",
    "topic",
    "partition",
    "offset",
    "timestamp"
).show(truncate=False)
```

#### 4. Structured Streaming ã®ãƒ†ã‚¹ãƒˆ

```python
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èª­ã¿è¾¼ã¿
streaming_df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9092") \
    .option("subscribe", "test-topic") \
    .option("startingOffsets", "earliest") \
    .load()

parsed_df = streaming_df.selectExpr(
    "CAST(key AS STRING) as key",
    "CAST(value AS STRING) as value",
    "timestamp"
)

# ãƒ¡ãƒ¢ãƒªã‚·ãƒ³ã‚¯ã«æ›¸ãè¾¼ã¿
query = parsed_df.writeStream \
    .format("memory") \
    .queryName("test_stream") \
    .outputMode("append") \
    .start()

# çµæœç¢ºèª
import time
time.sleep(5)
spark.sql("SELECT * FROM test_stream").show(truncate=False)

# åœæ­¢
query.stop()
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Kafka connector ãŒè¦‹ã¤ã‹ã‚‰ãªã„

```
AnalysisException: Failed to find data source: kafka.
```

`spark-defaults.conf` ãŒæ­£ã—ããƒã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ï¼š

```bash
docker exec spark-iceberg cat /opt/spark/conf/spark-defaults.conf | grep kafka
```

`spark.jars.packages` ã®è¡ŒãŒè¡¨ç¤ºã•ã‚Œã‚Œã° OK ã§ã™ã€‚è¡¨ç¤ºã•ã‚Œãªã„å ´åˆã¯ã€`docker compose down` ã—ã¦ã‹ã‚‰å†åº¦ `docker compose up -d` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

### MinIO ã«æ¥ç¶šã§ããªã„

MinIO ã®èµ·å‹•ã‚’å¾…ã£ã¦ã‹ã‚‰ä»–ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚`mc` ã‚³ãƒ³ãƒ†ãƒŠãŒ `Bucket created successfully` ã‚’å‡ºåŠ›ã—ã¦ã„ã‚Œã°æ­£å¸¸ã§ã™ï¼š

```bash
docker compose logs mc
```

## ã¾ã¨ã‚

æœ¬è¨˜äº‹ã§ã¯ã€Spark Structured Streaming + Kafka + Iceberg ã®ãƒ­ãƒ¼ã‚«ãƒ«æ¤œè¨¼ç’°å¢ƒã‚’ Docker Compose ã§æ§‹ç¯‰ã—ã¾ã—ãŸã€‚

æ§‹ç¯‰ã—ãŸç’°å¢ƒã§ç¢ºèªã§ããŸã“ã¨ï¼š
- SparkSession ã‹ã‚‰ Iceberg REST Catalog ã¸ã®æ¥ç¶š
- Kafka ã¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€å—ä¿¡
- Structured Streaming ã«ã‚ˆã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒ èª­ã¿è¾¼ã¿

æ¬¡å›ã¯ã€ã“ã®ç’°å¢ƒã‚’ä½¿ã£ã¦ Structured Streaming ã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ï¼ˆKafka ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ã€Iceberg ã¸ã®æ›¸ãè¾¼ã¿ï¼‰ã‚’è§£èª¬ã—ã¾ã™ã€‚

## å‚è€ƒãƒªãƒ³ã‚¯

- [Apache Iceberg - Spark Configuration](https://iceberg.apache.org/docs/latest/spark-configuration/)
- [Spark Structured Streaming + Kafka Integration](https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html)
- [tabulario/spark-iceberg Docker Image](https://github.com/tabular-io/docker-spark-iceberg)
