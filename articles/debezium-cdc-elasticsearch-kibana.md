---
title: "Debezium CDC å®Ÿè·µç·¨ - Elasticsearch + Kibanaã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–"
emoji: "ğŸ“Š"
type: "tech"
topics: ["debezium", "cdc", "elasticsearch", "kibana", "kafka"]
published: false
---

## ã¯ã˜ã‚ã«

å‰å›ã®è¨˜äº‹ã§ã¯ã€Debezium ã‚’ä½¿ã£ã¦ MySQL ã®å¤‰æ›´ãƒ‡ãƒ¼ã‚¿ã‚’ PostgreSQL ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒæœŸã§ãã‚‹ã‹æ¤œè¨¼ã—ã¾ã—ãŸã€‚

https://zenn.dev/toshiro3/articles/debezium-cdc-introduction

ä»Šå›ã¯ã€åŒã˜ CDC ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ‹¡å¼µã—ã¦ã€**Elasticsearch + Kibana** ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–ãŒã§ãã‚‹ã‹æ¤œè¨¼ã—ã¦ã¿ã¾ã™ã€‚

### ä»Šå›ã®ã‚´ãƒ¼ãƒ«

- MySQL ã®å¤‰æ›´ã‚’ Elasticsearch ã«è‡ªå‹•åŒæœŸ
- Kibana ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–
- INSERT / UPDATE ãŒå³åº§ã«åæ˜ ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MySQL  â”‚â”€â”€â”€â–¶â”‚  Debezium â”‚â”€â”€â”€â–¶â”‚  Kafka  â”‚â”€â”€â”€â–¶â”‚ Elasticsearch  â”‚â”€â”€â”€â–¶â”‚     Kibana      â”‚
â”‚ (binlog)â”‚    â”‚  Source   â”‚    â”‚ (Topic) â”‚    â”‚ Sink Connector â”‚    â”‚  (ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚ PostgreSQL â”‚  â€» å‰å›ã®è¨˜äº‹ã§æ§‹ç¯‰æ¸ˆã¿
                               â”‚    Sink    â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

å‰å›ã®æ§‹æˆã« **Elasticsearch** ã¨ **Kibana** ã‚’è¿½åŠ ã—ã€Kafka ã‹ã‚‰ Elasticsearch ã¸ã® Sink Connector ã‚’è¨­å®šã—ã¾ã™ã€‚

## ç’°å¢ƒæ§‹ç¯‰

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
debezium-cdc-elasticsearch-kibana/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ connect/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pom.xml
â”œâ”€â”€ mysql/
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ 01_init.sql
â””â”€â”€ postgres/
    â””â”€â”€ init/
        â””â”€â”€ 01_init.sql
```

### å‰å›ã‹ã‚‰ã®ä¸»ãªå¤‰æ›´ç‚¹

1. **Elasticsearch / Kibana ã‚³ãƒ³ãƒ†ãƒŠã®è¿½åŠ **
2. **Kafka Connect ã® Dockerfile å¤‰æ›´**ï¼ˆMaven ã‚’ä½¿ã£ãŸãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ï¼‰
3. **Elasticsearch Sink Connector ç”¨ã®ä¾å­˜é–¢ä¿‚è¿½åŠ **

### Dockerfileï¼ˆconnect/Dockerfileï¼‰

å‰å›ã¯ curl ã§ç›´æ¥ JAR ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã—ãŸãŒã€Elasticsearch Sink Connector ã¯ä¾å­˜é–¢ä¿‚ãŒè¤‡é›‘ãªãŸã‚ã€**Maven ã‚’ä½¿ã£ãŸãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰**ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚

```dockerfile
# Stage 1: Maven ã§ä¾å­˜é–¢ä¿‚ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
FROM maven:3.9-eclipse-temurin-21 AS builder

WORKDIR /build

COPY pom.xml .

# ä¾å­˜é–¢ä¿‚ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
RUN mvn dependency:copy-dependencies -DoutputDirectory=/build/libs

# Stage 2: Debezium Connect ã« jar ã‚’è¿½åŠ 
FROM debezium/connect:2.7.3.Final

USER root

# Elasticsearch Sink Connectorï¼ˆå…¨ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’ã¾ã¨ã‚ã¦ã‚³ãƒ”ãƒ¼ï¼‰
RUN mkdir -p /kafka/connect/kafka-connect-elasticsearch
COPY --from=builder /build/libs/*.jar /kafka/connect/kafka-connect-elasticsearch/

# JDBC Sink Connectorï¼ˆå¿…è¦ãª jar ã®ã¿ã‚³ãƒ”ãƒ¼ï¼‰
RUN mkdir -p /kafka/connect/kafka-connect-jdbc
COPY --from=builder /build/libs/kafka-connect-jdbc-*.jar /kafka/connect/kafka-connect-jdbc/
COPY --from=builder /build/libs/postgresql-*.jar /kafka/connect/kafka-connect-jdbc/

USER kafka
```

:::message
Maven ã® `dependency:copy-dependencies` ã§å…¨ã¦ã®ä¾å­˜é–¢ä¿‚ãŒ `/build/libs/` ã«é›†ç´„ã•ã‚Œã‚‹ãŸã‚ã€`kafka-connect-elasticsearch` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ JDBC é–¢é€£ã® JAR ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚æœ¬æ¥ã¯ä¸è¦ã§ã™ãŒã€å‹•ä½œæ¤œè¨¼ã®è¦³ç‚¹ã§ã¯å•é¡Œãªã„ã¨åˆ¤æ–­ã—ã¦ã„ã¾ã™ã€‚
:::

### pom.xmlï¼ˆconnect/pom.xmlï¼‰

Maven ã§å¿…è¦ãª Connector ã¨ä¾å­˜é–¢ä¿‚ã‚’å®šç¾©ã—ã¾ã™ã€‚

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <groupId>com.example</groupId>
    <artifactId>kafka-connect-deps</artifactId>
    <version>1.0.0</version>
    <packaging>pom</packaging>

    <dependencies>
        <!-- Elasticsearch Sink Connector -->
        <dependency>
            <groupId>io.confluent</groupId>
            <artifactId>kafka-connect-elasticsearch</artifactId>
            <version>15.0.0</version>
        </dependency>
        <!-- JDBC Sink Connector -->
        <dependency>
            <groupId>io.confluent</groupId>
            <artifactId>kafka-connect-jdbc</artifactId>
            <version>10.7.4</version>
        </dependency>
        <!-- PostgreSQL JDBC Driver -->
        <dependency>
            <groupId>org.postgresql</groupId>
            <artifactId>postgresql</artifactId>
            <version>42.7.1</version>
        </dependency>
    </dependencies>

    <repositories>
        <repository>
            <id>confluent</id>
            <url>https://packages.confluent.io/maven/</url>
        </repository>
    </repositories>
</project>
```

:::message
Confluent ã® Kafka Connect ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã¯ã€Maven Central ã§ã¯ãªã Confluent ã®ãƒªãƒã‚¸ãƒˆãƒªã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€`<repositories>` ã®è¨­å®šãŒå¿…è¦ã§ã™ã€‚
:::

### docker-compose.yml

å‰å›ã®æ§‹æˆã« Elasticsearch ã¨ Kibana ã‚’è¿½åŠ ã—ã¾ã™ã€‚

:::message
Kafka 3ç³»ï¼ˆKRaft ãƒ¢ãƒ¼ãƒ‰ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€Zookeeper ã¯ä¸è¦ã§ã™ã€‚
:::

```yaml
services:
  # ========================================
  # Source Database
  # ========================================
  mysql:
    image: mysql:8.0
    container_name: mysql
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: inventory
      MYSQL_USER: debezium
      MYSQL_PASSWORD: debezium
    command:
      - --server-id=1
      - --log-bin=mysql-bin
      - --binlog-format=ROW
      - --binlog-row-image=FULL
      - --gtid-mode=ON
      - --enforce-gtid-consistency=ON
    volumes:
      - ./mysql/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-prootpassword"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ========================================
  # Kafka with KRaft (No Zookeeper)
  # ========================================
  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      # KRaftè¨­å®š
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
      # ãƒªã‚¹ãƒŠãƒ¼è¨­å®š
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,EXTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      # ãã®ä»–
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 > /dev/null 2>&1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  # ========================================
  # Kafka Connect with Debezium + Sink Connectors
  # ========================================
  connect:
    build: ./connect
    container_name: connect
    ports:
      - "8083:8083"
    environment:
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
      BOOTSTRAP_SERVERS: kafka:9092
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
    depends_on:
      kafka:
        condition: service_healthy
      mysql:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy

  # ========================================
  # Kafka UI
  # ========================================
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: debezium
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://connect:8083
    depends_on:
      - kafka
      - connect

  # ========================================
  # Sink Database (PostgreSQL)
  # ========================================
  postgres:
    image: postgres:15
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: cdc_sink
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - ./postgres/init:/docker-entrypoint-initdb.d

  # ========================================
  # Elasticsearch
  # ========================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
    container_name: elasticsearch
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q 'green\\|yellow'"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s

  # ========================================
  # Kibana
  # ========================================
  kibana:
    image: docker.elastic.co/kibana/kibana:8.12.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      elasticsearch:
        condition: service_healthy
```

#### docker-compose.yml ã®ãƒã‚¤ãƒ³ãƒˆ

| é …ç›® | èª¬æ˜ |
|------|------|
| **KRaft ãƒ¢ãƒ¼ãƒ‰** | Kafka 3ç³»ã§ã¯ Zookeeper ãŒä¸è¦ã€‚`KAFKA_PROCESS_ROLES: broker,controller` ã§è¨­å®š |
| **healthcheck** | å„ã‚µãƒ¼ãƒ“ã‚¹ã®èµ·å‹•å®Œäº†ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ä¾å­˜ã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹• |
| **condition: service_healthy** | healthcheck ãŒæˆåŠŸã™ã‚‹ã¾ã§å¾…æ©Ÿã—ã¦ã‹ã‚‰èµ·å‹• |

### èµ·å‹•

```bash
docker compose up -d --build
```

å…¨ã¦ã®ã‚³ãƒ³ãƒ†ãƒŠãŒèµ·å‹•ã™ã‚‹ã¾ã§å¾…ã¡ã¾ã™ï¼ˆç‰¹ã« Elasticsearch ã¯èµ·å‹•ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰ã€‚

```bash
docker compose ps
```

## Connector è¨­å®š

### 1. Source Connectorï¼ˆMySQL â†’ Kafkaï¼‰

å‰å›ã¨åŒã˜è¨­å®šã§ã™ã€‚

```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "inventory-connector",
    "config": {
      "connector.class": "io.debezium.connector.mysql.MySqlConnector",
      "tasks.max": "1",
      "database.hostname": "mysql",
      "database.port": "3306",
      "database.user": "debezium",
      "database.password": "debezium",
      "database.server.id": "184054",
      "topic.prefix": "dbserver1",
      "database.include.list": "inventory",
      "schema.history.internal.kafka.bootstrap.servers": "kafka:9092",
      "schema.history.internal.kafka.topic": "schema-changes.inventory",
      "include.schema.changes": "true",
      "time.precision.mode": "connect"
    }
  }'
```

### 2. JDBC Sink Connectorï¼ˆKafka â†’ PostgreSQLï¼‰

å‰å›ã¨åŒã˜è¨­å®šã§ã™ã€‚

```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "jdbc-sink-connector",
    "config": {
      "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
      "tasks.max": "1",
      "connection.url": "jdbc:postgresql://postgres:5432/cdc_sink",
      "connection.user": "postgres",
      "connection.password": "postgres",
      "topics": "dbserver1.inventory.customers",
      "table.name.format": "customers_cdc",
      "insert.mode": "upsert",
      "pk.mode": "record_key",
      "pk.fields": "id",
      "auto.create": "true",
      "auto.evolve": "true",
      "transforms": "unwrap",
      "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
      "transforms.unwrap.drop.tombstones": "true"
    }
  }'
```

### 3. Elasticsearch Sink Connectorï¼ˆKafka â†’ Elasticsearchï¼‰

ä»Šå›è¿½åŠ ã™ã‚‹ Connector ã§ã™ã€‚

```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "elasticsearch-sink-customers",
    "config": {
      "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
      "tasks.max": "1",
      "connection.url": "http://elasticsearch:9200",
      "topics": "dbserver1.inventory.customers",
      "key.ignore": "false",
      "schema.ignore": "true",
      "behavior.on.null.values": "delete",
      "transforms": "unwrap,extractKey",
      "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
      "transforms.unwrap.drop.tombstones": "false",
      "transforms.unwrap.delete.handling.mode": "none",
      "transforms.extractKey.type": "org.apache.kafka.connect.transforms.ExtractField$Key",
      "transforms.extractKey.field": "id"
    }
  }'
```

#### è¨­å®šã®ãƒã‚¤ãƒ³ãƒˆ

| è¨­å®š | å€¤ | èª¬æ˜ |
|------|-----|------|
| `key.ignore` | `false` | Kafka ã®ã‚­ãƒ¼ã‚’ Elasticsearch ã® `_id` ã¨ã—ã¦ä½¿ç”¨ |
| `schema.ignore` | `true` | ã‚¹ã‚­ãƒ¼ãƒã‚’ç„¡è¦–ã—ã¦JSONã¨ã—ã¦å‡¦ç† |
| `behavior.on.null.values` | `delete` | DELETE ã‚¤ãƒ™ãƒ³ãƒˆæ™‚ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ |
| `transforms.unwrap` | ExtractNewRecordState | Debezium ã®ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã‹ã‚‰ `after` ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º |
| `transforms.unwrap.drop.tombstones` | `false` | tombstone ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä¿æŒï¼ˆDELETEæ¤œçŸ¥ç”¨ï¼‰ |
| `transforms.unwrap.delete.handling.mode` | `none` | DELETEæ™‚ã¯nullã‚’æ¸¡ã™ï¼ˆbehavior.on.null.valuesã§å‡¦ç†ï¼‰ |
| `transforms.extractKey` | ExtractField$Key | ã‚­ãƒ¼ã‹ã‚‰ `id` ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º |

### Connector çŠ¶æ…‹ç¢ºèª

```bash
curl -s http://localhost:8083/connectors?expand=status | jq
```

3ã¤ã® Connector ãŒ `RUNNING` ã«ãªã£ã¦ã„ã‚Œã° OK ã§ã™ã€‚

## Elasticsearch ã§ã®å‹•ä½œç¢ºèª

Kibana ã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã™ã‚‹å‰ã«ã€CLI ã§ CDC ãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚

### INSERT ã®ç¢ºèª

MySQL ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã€Elasticsearch ã«åŒæœŸã•ã‚Œã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚

```bash
# INSERT
docker compose exec mysql mysql -u debezium -pdebezium inventory -e "
INSERT INTO customers (first_name, last_name, email) 
VALUES ('Jiro', 'Sato', 'jiro.sato@example.com');
"

# ç¢ºèª
sleep 2
curl -s 'http://localhost:9200/dbserver1.inventory.customers/_search?pretty' | jq '.hits.hits[]._source.first_name'
```

è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿ãŒ Elasticsearch ã«åæ˜ ã•ã‚Œã¦ã„ã‚Œã°æˆåŠŸã§ã™ã€‚

### UPDATE ã®ç¢ºèª

```bash
# UPDATE
docker compose exec mysql mysql -u debezium -pdebezium inventory -e "
UPDATE customers SET first_name = 'Taro-Updated' WHERE id = 1;
"

# ç¢ºèª
sleep 2
curl -s 'http://localhost:9200/dbserver1.inventory.customers/_doc/1?pretty'
```

`first_name` ãŒ `Taro-Updated` ã«å¤‰ã‚ã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚

### DELETE ã®ç¢ºèª

```bash
# DELETE
docker compose exec mysql mysql -u debezium -pdebezium inventory -e "
DELETE FROM customers WHERE id = 3;
"

# ç¢ºèª
sleep 2
curl -s 'http://localhost:9200/dbserver1.inventory.customers/_search?pretty' | jq '.hits.total.value'
```

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ãŒæ¸›ã£ã¦ã„ã‚Œã°ã€DELETE ã‚‚æ­£ã—ãåŒæœŸã•ã‚Œã¦ã„ã¾ã™ã€‚

## Kibana ã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ

### 1. Kibana ã«ã‚¢ã‚¯ã‚»ã‚¹

```
http://localhost:5601
```

### 2. Data View ã®ä½œæˆ

1. å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ **â‰¡** â†’ **Management** â†’ **Stack Management**
2. **Kibana** â†’ **Data Views**
3. **Create data view** ã‚’ã‚¯ãƒªãƒƒã‚¯
4. è¨­å®šï¼š
   - **Name**: `customers`
   - **Index pattern**: `dbserver1.inventory.customers`
   - **Timestamp field**: é¸æŠã—ãªã„ï¼ˆã¾ãŸã¯ `updated_at`ï¼‰
5. **Save data view to Kibana**

### 3. Discover ã§ãƒ‡ãƒ¼ã‚¿ç¢ºèª

1. å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ **â‰¡** â†’ **Analytics** â†’ **Discover**
2. ä½œæˆã—ãŸ Data View `customers` ã‚’é¸æŠ
3. MySQL ã‹ã‚‰åŒæœŸã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

![Discoverç”»é¢](/images/debezium-cdc-elasticsearch-kibana/discover.png)

### 4. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ

1. å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ **â‰¡** â†’ **Analytics** â†’ **Dashboard**
2. **Create dashboard** ã‚’ã‚¯ãƒªãƒƒã‚¯

#### å¯è¦–åŒ–1: é¡§å®¢ä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«

1. **Create visualization** ã‚’ã‚¯ãƒªãƒƒã‚¯
2. **Visualization type**: `Table`
3. å·¦å´ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰ **Rows** ã«è¿½åŠ ï¼š
   - `first_name`
   - `last_name`
   - `email`
4. **Save and return**

#### å¯è¦–åŒ–2: ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ãƒ¡ãƒˆãƒªãƒƒã‚¯

1. å†åº¦ **Create visualization** ã‚’ã‚¯ãƒªãƒƒã‚¯
2. **Visualization type**: `Metric`
3. **Primary metric**: `Count`ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
4. **Save and return**

#### ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä¿å­˜

1. å³ä¸Šã® **Save** ã‚’ã‚¯ãƒªãƒƒã‚¯
2. ã‚¿ã‚¤ãƒˆãƒ«: `CDC Customers Dashboard`
3. **Save**

## ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒæœŸã®ãƒ‡ãƒ¢

ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã—ãŸçŠ¶æ…‹ã§ã€MySQL ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ã€Kibana ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§åæ˜ ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚

### INSERT ã®ç¢ºèª

```bash
docker compose exec mysql mysql -u debezium -pdebezium inventory -e "
INSERT INTO customers (first_name, last_name, email) 
VALUES ('Saburo', 'Tanaka', 'saburo.tanaka@example.com');
"
```

Kibana ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã® **ğŸ”„ï¼ˆãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ï¼‰** ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€è¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

![INSERTå¾Œã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰](/images/debezium-cdc-elasticsearch-kibana/after-insert.png)

### UPDATE ã®ç¢ºèª

```bash
docker compose exec mysql mysql -u debezium -pdebezium inventory -e "
UPDATE customers SET first_name = 'Hanako-Updated' WHERE id = 2;
"
```

å†åº¦ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã™ã‚‹ã¨ã€`Hanako` ãŒ `Hanako-Updated` ã«å¤‰ã‚ã£ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã™ã€‚

![UPDATEå¾Œã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰](/images/debezium-cdc-elasticsearch-kibana/after-update.png)

## PostgreSQL vs Elasticsearch ã®ä½¿ã„åˆ†ã‘

PostgreSQL Sink ã¨ Elasticsearch Sink ã®ä½¿ã„åˆ†ã‘ã‚’æ•´ç†ã—ã¾ã™ã€‚

| è¦³ç‚¹ | PostgreSQL | Elasticsearch |
|------|------------|---------------|
| **ç”¨é€”** | ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å‡¦ç†ã€ãƒ¬ãƒãƒ¼ãƒˆ | å…¨æ–‡æ¤œç´¢ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ |
| **ã‚¯ã‚¨ãƒª** | SQL | DSL / KQL |
| **å¯è¦–åŒ–** | å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ãŒå¿…è¦ | Kibana ãŒçµ±åˆæ¸ˆã¿ |
| **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£** | å‚ç›´ã‚¹ã‚±ãƒ¼ãƒ«ä¸­å¿ƒ | æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒ«ãŒå®¹æ˜“ |
| **ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§** | ACID æº–æ‹  | çµæœæ•´åˆæ€§ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ1ç§’ã® refresh intervalï¼‰ |
| **é©ã—ãŸã‚±ãƒ¼ã‚¹** | ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿åŒæœŸã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— | ãƒ­ã‚°åˆ†æã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ |

:::message
Elasticsearch ã¯çµæœæ•´åˆæ€§ã®ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿åæ˜ ã«è‹¥å¹²ã®ãƒ©ã‚°ãŒã‚ã‚Šã¾ã™ã€‚æ¤œè¨¼ã‚³ãƒãƒ³ãƒ‰ã§ `sleep 2` ã‚’å…¥ã‚Œã¦ã„ã‚‹ã®ã¯ã“ã®ãŸã‚ã§ã™ã€‚
:::

## ã¾ã¨ã‚

Debezium CDC ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã« Elasticsearch + Kibana ã‚’è¿½åŠ ã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–ãŒã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚

### ä»Šå›ã®ãƒã‚¤ãƒ³ãƒˆ

- **Maven ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰**ã§ Kafka Connect ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®ä¾å­˜é–¢ä¿‚ã‚’è§£æ±º
- **Elasticsearch Sink Connector** ã§ CDC ã‚¤ãƒ™ãƒ³ãƒˆã‚’ Elasticsearch ã«åŒæœŸ
- **Kibana ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**ã§ INSERT / UPDATE ãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«åæ˜ ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

CDC ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å¤‰æ›´ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«æ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ ã¸é€£æºã§ãã¾ã™ã€‚åˆ†æåŸºç›¤ã‚„ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹é–“ã®ãƒ‡ãƒ¼ã‚¿åŒæœŸãªã©ã€å¹…åºƒã„ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¿œç”¨ã§ãã‚‹ã§ã—ã‚‡ã†ã€‚
